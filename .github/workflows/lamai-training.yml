name: LamAI Training Pipeline

on:
  workflow_dispatch:
    inputs:
      epochs:
        description: 'Number of training epochs'
        required: true
        default: '5'
        type: string
      save_dir:
        description: 'Directory to save training outputs'
        required: true
        default: 'outputs/'
        type: string

jobs:
  train-lamai:
    runs-on: self-hosted
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: System info and setup
      run: |
        echo "ðŸ–¥ï¸ System Information:"
        uname -a
        lscpu | grep "Architecture\|Model name"
        python3 --version
        pip3 --version
        
    - name: Install system dependencies for Linux x64
      run: |
        sudo apt-get update
        sudo apt-get install -y python3-dev python3-pip build-essential
        sudo apt-get install -y libffi-dev libssl-dev
        
    - name: Install Python ML dependencies
      run: |
        pip3 install --upgrade pip setuptools wheel
        pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
        pip3 install transformers sentence-transformers datasets
        pip3 install faiss-cpu numpy pandas scikit-learn
        pip3 install flask flask-cors requests beautifulsoup4
        pip3 install wikipedia spacy textblob
        
    - name: Verify installations
      run: |
        python3 -c "import torch; print(f'PyTorch version: {torch.__version__}')"
        python3 -c "import transformers; print(f'Transformers version: {transformers.__version__}')"
        python3 -c "import sentence_transformers; print(f'Sentence-transformers version: {sentence_transformers.__version__}')"
        python3 -c "import faiss; print('FAISS installed successfully')"
            
    - name: Verify GPU availability
      run: |
        echo "ðŸ” Checking GPU availability..."
        python3 -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'GPU count: {torch.cuda.device_count()}'); print(f'GPU name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\"}')"
        if command -v nvidia-smi >/dev/null 2>&1; then
          echo "ðŸ“Š GPU Memory Info:"
          nvidia-smi
        else
          echo "âš ï¸ nvidia-smi not available (CPU-only mode)"
        fi
    
    - name: Run massive training
      run: |
        echo "ðŸš€ Starting LamAI training with ${{ github.event.inputs.epochs }} epochs..."
        python3 massive_trainer.py --epochs ${{ github.event.inputs.epochs }} --save_dir ${{ github.event.inputs.save_dir }}
      env:
        PYTHONPATH: ${{ github.workspace }}
        TOKENIZERS_PARALLELISM: false
        CUDA_VISIBLE_DEVICES: "0"
    
    - name: Check training outputs
      run: |
        ls -la ${{ github.event.inputs.save_dir }}
        echo "Training completed successfully!"
    
    - name: Configure Git
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
    
    - name: Commit and push training outputs
      run: |
        git add ${{ github.event.inputs.save_dir }}
        git add vector_db/
        git add *.json
        git add *.faiss
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          git commit -m "ðŸš€ Training completed: epochs=${{ github.event.inputs.epochs }}, outputs saved to ${{ github.event.inputs.save_dir }}"
          git push
        fi
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Create training summary
      run: |
        echo "## ðŸ§  LamAI Training Completed" >> $GITHUB_STEP_SUMMARY
        echo "- **Epochs:** ${{ github.event.inputs.epochs }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Output Directory:** ${{ github.event.inputs.save_dir }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Timestamp:** $(date)" >> $GITHUB_STEP_SUMMARY
        echo "- **GPU Used:** $(python3 -c "import torch; print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU')")" >> $GITHUB_STEP_SUMMARY
        if [ -f "${{ github.event.inputs.save_dir }}/training_log.txt" ]; then
          echo "- **Training Log:**" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          tail -20 "${{ github.event.inputs.save_dir }}/training_log.txt" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
        fi
    
    - name: Stop self-hosted runner
      if: always()
      run: |
        echo "ðŸ›‘ Training pipeline completed. Shutting down runner..."
        echo "ðŸ“Š Final disk usage:"
        df -h
        echo "ðŸ”„ Cleaning up cache..."
        rm -rf ~/.cache/huggingface || true
        # Kill the runner process to stop the Colab session
        sudo systemctl stop actions.runner.* || true
        pkill -f "Runner.Listener" || true
        echo "âœ… Runner shutdown initiated"